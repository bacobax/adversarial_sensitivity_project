import torch
from typing import Any
import torch.nn.functional as F
import matplotlib.pyplot as plt


def _to_device_tensor(x: Any, device: str = "cpu") -> torch.Tensor:
    """Convert numpy/sequence/torch.Tensor to a torch.Tensor on device.

    Keeps tensors unchanged besides device transfer. Adds batch dim if missing
    for images/masks with shape (C,H,W).
    """
    if isinstance(x, torch.Tensor):
        t = x.to(device)
    else:
        t = torch.as_tensor(x).to(device)

    # If tensor has shape (C,H,W) assume single sample, add batch dim
    if t.ndim == 3:
        t = t.unsqueeze(0)

    return t


def get_vulnerability_map(image, mask_inpainting, detector_model, device: str = "cpu"):
    mask_inpainting = _to_device_tensor(mask_inpainting, device)
    image = _to_device_tensor(image, device).float()

    # Ensure only the image requires grad. Detach/clone to avoid enabling grad for upstream tensors.
    image = image.clone().detach().to(device)
    image.requires_grad_(True)

    # Call the detector normally (grad only flows to image)
    # Keep the batch dimension so downstream code can decide whether the
    # model produced multi-class logits ([B, C]) or single-logit outputs
    # ([B, 1] or [B]). Indexing the batch (e.g. [0]) here would turn a
    # (1, C) tensor into a 1D tensor with shape (C,) and make the later
    # dimensionality checks unreliable. Keep the full output.
    results = detector_model(image)

    # Compute a loss that enforces the ground-truth class == 1 (all images are AI-generated)
    # We support both multi-class logits (shape [B, C]) and binary logits ([B, 1] or [B]).
    if not isinstance(results, torch.Tensor):
        # try to convert; if this fails, let it raise a clear error
        results = torch.as_tensor(results).to(device)

    # loss calculation
    if results.dim() == 2 and results.size(1) > 1:
        # multi-class logits -> use cross-entropy with label 1
        target = torch.ones(results.size(0), dtype=torch.long, device=device)
        loss = F.cross_entropy(results, target)
    else:
        # binary logits (or single-logit output). Squeeze to shape (B,)
        logits = results.squeeze()
        # If batch dim missing and single sample, make a batch of size 1
        if logits.ndim == 0:
            logits = logits.unsqueeze(0)
        target = torch.ones_like(logits, device=device)
        loss = F.binary_cross_entropy_with_logits(logits, target)

    # Backpropagate so image.grad is populated
    loss.backward()

    

    # Build a vulnerability map from the image gradients. Sum absolute gradient across channels.
    # Result shape: (B, 1, H, W)
    if image.grad is None:
        vuln_map = torch.zeros((image.size(0), 1, image.size(2), image.size(3)), device=device)
    else:
        vuln_map = image.grad.detach().abs().sum(dim=1, keepdim=True)

    # Return the vulnerability map (on CPU) and the raw detector results for
    # further use. Detach and move results to CPU to avoid holding device
    # tensors with grad history in callers.
    return vuln_map.cpu(), results.detach().cpu()

def visualize_vulnerability_map(vuln_map: torch.Tensor, image: torch.Tensor | None = None, image_strength: float = 0.05) -> torch.Tensor:
    """Convert a vulnerability map to a visualizable overlay on the original image.

    The visualization intentionally darkens the original image strongly so the
    vulnerability (red) points stand out. If `image` is provided it will overlay
    a red heatmap representing `vuln_map` on top of a darkened image. If
    `image` is None, the function returns a 3-channel visualization of the
    normalized vulnerability map.

    Args:
        vuln_map: Tensor, shape (B, 1, H, W) or (B, H, W)
        image: Optional Tensor, shape (B, 3, H, W) or (3, H, W). Expected range [0,1] or [0,255].
        image_strength: How much of the original image to keep (0.0..1.0). Small
            values (e.g. 0.05) make the image nearly black so heatmap points are
            clearly visible.

    Returns:
        Tensor of shape (B, 3, H, W), values in [0, 1].
    """
    # Ensure vuln_map has shape (B,1,H,W)
    if vuln_map.ndim == 3:
        vuln_map = vuln_map.unsqueeze(1)

    # Normalize each map to [0, 1]
    vmin = vuln_map.amin(dim=(2, 3), keepdim=True)
    vmax = vuln_map.amax(dim=(2, 3), keepdim=True)
    norm_map = (vuln_map - vmin) / (vmax - vmin + 1e-8)

    # If no image provided, return a 3-channel gray->RGB map (all channels equal)
    if image is None:
        vis_map = norm_map.repeat(1, 3, 1, 1)
        return vis_map.clamp(0.0, 1.0)

    # Prepare image tensor
    img = image
    if img.ndim == 3:
        # add batch dim
        img = img.unsqueeze(0)

    # Move to same device
    img = img.to(norm_map.device).float()

    # If image in [0,255], scale to [0,1]
    if img.max() > 2.0:
        img = img / 255.0

    # Ensure image has 3 channels
    if img.size(1) == 1:
        img = img.repeat(1, 3, 1, 1)

    # Create a red heatmap from norm_map: heatmap = (R,G,B) with R=norm, G=R*0.2, B=0
    heat = torch.zeros_like(img)
    heat_r = norm_map.squeeze(1)
    # expand to (B,1,H,W) then broadcast
    heat[:, 0:1, :, :] = heat_r
    heat[:, 1:2, :, :] = heat_r * 0.2
    heat[:, 2:3, :, :] = 0.0

    # Darken the original image so heatmap points are more visible.
    image_strength = float(image_strength)
    image_strength = max(0.0, min(1.0, image_strength))
    heat_strength = 1.0 - image_strength

    overlay = img * image_strength + heat * heat_strength

    return overlay.clamp(0.0, 1.0)

def plot_triple_res(image, vuln_map, mask):
    """Plot original image, vulnerability map visualization, and mask.

    This function is batch-size independent: if inputs have a batch dimension
    (B, C, H, W) it will plot each sample as a row with three columns.
    """
    # Ensure tensors have batch dimension
    if image.ndim == 3:
        image = image.unsqueeze(0)
    if vuln_map.ndim == 3:
        vuln_map = vuln_map.unsqueeze(0)
    if mask.ndim == 3:
        mask = mask.unsqueeze(0)

    B = image.size(0)

    # Prepare visualization map: if vuln_map is single-channel, convert to 3-channel vis
    if vuln_map.ndim == 4 and vuln_map.size(1) == 1:
        vis_map = visualize_vulnerability_map(vuln_map, image=None)
    else:
        # assume vuln_map is already a 3-channel visualization
        vis_map = vuln_map
        if vis_map.ndim == 3:
            vis_map = vis_map.unsqueeze(0)

    # Create subplots: rows = B, cols = 3
    fig, axes = plt.subplots(B, 3, figsize=(3 * 4, max(1, B) * 4))

    # Normalize axes shape to [B,3]
    if B == 1:
        axes = axes.reshape(1, 3)

    for i in range(B):
        ax0 = axes[i, 0]
        ax1 = axes[i, 1]
        ax2 = axes[i, 2]

        # Original image: ensure shape (3,H,W) and values in [0,1]
        print(f"image shape: {image.shape}, vuln_map shape: {vuln_map.shape}, mask shape: {mask.shape}")
        img = image[i].cpu().float()
        if img.max() > 2.0:
            img = img / 255.0
        if img.size(0) == 1:
            img = img.repeat(3, 1, 1)
        ax0.imshow(img.permute(1, 2, 0).numpy())
        ax0.set_title(f"Original Image {i}")
        ax0.axis('off')

        # Vulnerability visualization
        vm = vis_map[i].cpu().float()
        if vm.size(0) == 1:
            vm = vm.repeat(3, 1, 1)
        ax1.imshow(vm.permute(1, 2, 0).numpy())
        ax1.set_title("Vulnerability Map")
        ax1.axis('off')

        # Mask: reduce to (H,W)
        m = mask[i].cpu()
        if m.ndim == 3 and m.size(0) == 1:
            m_np = m.squeeze(0).numpy()
        elif m.ndim == 3 and m.size(0) == 3:
            # possibly RGB mask, convert to grayscale
            m_np = m.mean(0).numpy()
        else:
            m_np = m.numpy()
        ax2.imshow(m_np, cmap='gray')
        ax2.set_title("Inpainting Mask")
        ax2.axis('off')

    plt.tight_layout()
    plt.show()