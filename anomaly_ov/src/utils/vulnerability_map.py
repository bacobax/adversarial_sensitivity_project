import torch
from typing import Any
import torch.nn.functional as F
import matplotlib.pyplot as plt
from PIL import Image
def _to_device_tensor(x: Any, device: str = "cpu") -> torch.Tensor:
    """Convert numpy/sequence/torch.Tensor to a torch.Tensor on device.

    Keeps tensors unchanged besides device transfer. Adds batch dim if missing
    for images/masks with shape (C,H,W).
    """
    if isinstance(x, torch.Tensor):
        t = x.to(device)
    else:
        t = torch.as_tensor(x).to(device)

    # If tensor has shape (C,H,W) assume single sample, add batch dim
    if t.ndim == 3:
        t = t.unsqueeze(0)

    return t
def predict_with_model(model, image_tensor: torch.Tensor, device, max_side=1024, anomaly_map_size=(224, 224), input_gradient=False):
    """Run model and optionally compute vulnerability (gradient) maps.

    Args:
        model: Llava model instance
        image_tensor: Tensor [1, V, 3, H, W]
        device: torch.device for model
        max_side: (unused here, resizing done before this function)
        anomaly_map_size: tuple passed to model
        input_gradient: if True compute gradient-based vulnerability maps

    Returns:
        score (float), attn_maps (Tensor), anomaly_map (Tensor), vuln_maps (Tensor or empty list), image_tensor_detached
        vuln_maps shape: [1, V, 1, H, W] when input_gradient True
    """
    # Ensure tensor on device & dtype
    image_tensor = image_tensor.to(device=device, dtype=torch.bfloat16)
    if input_gradient:
        image_tensor.requires_grad_(input_gradient)


    # Forward
    final_preds, attn_maps, anomaly_map = model.get_anomaly_fetures_from_images(
        image_tensor,
        with_attention_map=True,
        anomaly_map_size=anomaly_map_size
    )

    vuln_maps = []
    if input_gradient:
        # Backward to populate image_tensor.grad (shape [1, V, 3, H, W])
        final_preds.backward()
        if image_tensor.grad is None:
            vuln_maps = torch.zeros((image_tensor.size(0), image_tensor.size(1), 1,
                                     image_tensor.size(3), image_tensor.size(4)), device=device)
        else:
            # Sum abs over channel dimension -> [1, V, 1, H, W]
            vuln_maps = image_tensor.grad.detach().abs().sum(dim=2, keepdim=True)

    score = float(final_preds.detach().to(torch.float32).cpu().numpy().reshape(-1)[0])
    return score, attn_maps, anomaly_map, vuln_maps, image_tensor.detach()
    

def _normalize_anomaly_maps_shape(anomaly_maps: torch.Tensor) -> torch.Tensor:
    """Normalize anomaly_maps to shape [V, 1, H, W] on the same device/dtype.

    Accepts [V,1,H,W], [1,V,1,H,W], or [V,H,W]. Returns float tensor.
    """
    if anomaly_maps is None:
        raise ValueError("anomaly_maps is None")
    am = anomaly_maps
    if am.ndim == 5 and am.shape[0] == 1:
        am = am[0]
    if am.ndim == 3:
        am = am.unsqueeze(1)
    if not (am.ndim == 4 and am.shape[1] == 1):
        raise ValueError(f"Unsupported anomaly_maps shape: {tuple(anomaly_maps.shape)}")
    return am.to(dtype=torch.float32)


def build_topk_mask(anomaly_maps: torch.Tensor, top_k: float = 0.1) -> torch.Tensor:
    """Build per-view top-k mask from anomaly maps.

    Args:
        anomaly_maps: Tensor in shape [V,1,H,W] or [1,V,1,H,W] or [V,H,W]
        top_k: fraction (0,1] of highest anomaly scores per view to keep

    Returns:
        mask: Tensor of shape [1, V, 1, H, W], values in {0,1}, dtype float32
    """
    am = _normalize_anomaly_maps_shape(anomaly_maps)  # [V,1,H,W]
    V, _, H, W = am.shape
    am_flat = am.view(V, -1)
    N = am_flat.shape[1]
    k_int = max(1, min(N, int(round(top_k * N))))
    # Get thresholds per view by kth value
    # Sort descending
    sorted_vals, _ = torch.sort(am_flat, dim=1, descending=True)
    thr = sorted_vals[torch.arange(V), k_int - 1].view(V, 1, 1, 1)
    mask_v = (am >= thr).to(torch.float32)  # [V,1,H,W]
    return mask_v.unsqueeze(0)  # [1,V,1,H,W]


def generate_noise_like(x: torch.Tensor, mode: str = "random", blur_kernel: int = 7) -> torch.Tensor:
    """Generate noise with the same shape as x ([1,V,3,H,W]).

    Modes:
        - 'random': standard normal noise
        - 'structured': low-frequency noise via average pooling (blur)
    """
    noise = torch.randn_like(x)
    if mode == "structured":
        B, V, C, H, W = noise.shape
        noise_reshaped = noise.view(B * V, C, H, W)
        pad = blur_kernel // 2
        noise_blur = F.avg_pool2d(noise_reshaped, kernel_size=blur_kernel, stride=1, padding=pad)
        noise = noise_blur.view(B, V, C, H, W)
    return noise


def apply_topk_attack(
    image_tensor: torch.Tensor,
    anomaly_maps: torch.Tensor,
    epsilon: float = 0.05,
    top_k: float = 0.5,
    noise_mode: str = "random",
    clamp_min: float = -1.0,
    clamp_max: float = 1.0,
) -> torch.Tensor:
    """Apply black-box top-k masked noise attack: x' = x + eps * M_topk âŠ™ eta.

    Args:
        image_tensor: [1, V, 3, H, W]
        anomaly_maps: [V,1,H,W] or [1,V,1,H,W] or [V,H,W]
        epsilon: norm bound multiplier for noise
        top_k: fraction of highest anomaly scores to mask-in
        noise_mode: 'random' or 'structured'
        clamp_min, clamp_max: clamp range for normalized images

    Returns:
        attacked image tensor with same shape/type/device as input
    """
    x = image_tensor
    assert x.ndim == 5 and x.shape[0] == 1 and x.shape[2] == 3, f"Unexpected image_tensor shape {tuple(x.shape)}"
    B, V, C, H, W = x.shape
    M = build_topk_mask(anomaly_maps, top_k=top_k).to(device=x.device)  # [1,V,1,H,W]
    eta = generate_noise_like(x, mode=noise_mode)
    perturb = epsilon * (M * eta)  # broadcast on channel dim
    x_adv = (x + perturb).clamp(clamp_min, clamp_max)
    return x_adv


def adversarial_recompute(
    model,
    image_tensor: torch.Tensor,
    original_anomaly_maps: torch.Tensor,
    device: str,
    epsilon: float = 0.05,
    top_k: float = 0.5,
    noise_mode: str = "random",
):
    """Create attacked image, re-run model, and get output_map = |a_map - a_map_adv|.

    Returns: attacked_image [1,V,3,H,W], anomaly_maps_adv [V,1,H,W], output_map [V,1,H,W]
    """
    x_adv = apply_topk_attack(image_tensor=image_tensor, anomaly_maps=original_anomaly_maps,
                              epsilon=epsilon, top_k=top_k, noise_mode=noise_mode)
    # infer desired anomaly map size from crops
    H, W = int(x_adv.shape[-2]), int(x_adv.shape[-1])
    with torch.no_grad():
        _, _, anomaly_maps_adv, _, _ = predict_with_model(
            model=model,
            image_tensor=x_adv,
            device=device,
            anomaly_map_size=(W, H),
        )
    am_orig = _normalize_anomaly_maps_shape(original_anomaly_maps)
    am_adv = _normalize_anomaly_maps_shape(anomaly_maps_adv)
    output_map = (am_orig - am_adv).abs()
    return x_adv, am_adv, output_map


def get_exp_map(
        image: Image, 
        detector_model, 
        is_resnet, 
        image_processor,
        process_images,
        max_side = 1024,
        device: str = "cpu"
    ):

    image = _to_device_tensor(image, device).float()

    # Ensure only the image requires grad. Detach/clone to avoid enabling grad for upstream tensors.
    image = image.clone().detach().to(device)
    image.requires_grad_(True)

    # Call the detector normally (grad only flows to image)
    # Keep the batch dimension so downstream code can decide whether the
    # model produced multi-class logits ([B, C]) or single-logit outputs
    # ([B, 1] or [B]). Indexing the batch (e.g. [0]) here would turn a
    # (1, C) tensor into a 1D tensor with shape (C,) and make the later
    # dimensionality checks unreliable. Keep the full output.

    results_full = predict_with_model(
        preprocessed_image=image,
        model_type='resnet50' if is_resnet else 'clip',
        cuda="cuda" in device,
        model=detector_model,
    )
    results = results_full[2]

    print(results_full)
    print(f"fake prob: {results_full[1][0,1]}")
    
    # Compute a loss that enforces the ground-truth class == 1 (all images are AI-generated)
    # We support both multi-class logits (shape [B, C]) and binary logits ([B, 1] or [B]).
    if not isinstance(results, torch.Tensor):
        # try to convert; if this fails, let it raise a clear error
        results = torch.as_tensor(results).to(device)

    # loss calculation
    if results.dim() == 2 and results.size(1) > 1:
        # multi-class logits -> use cross-entropy with label 1
        target = torch.ones(results.size(0), dtype=torch.long, device=device)
        loss = F.cross_entropy(results, target)
    else:
        # binary logits (or single-logit output). Squeeze to shape (B,)
        logits = results.squeeze()
        # If batch dim missing and single sample, make a batch of size 1
        if logits.ndim == 0:
            logits = logits.unsqueeze(0)
        target = torch.ones_like(logits, device=device)
        loss = F.binary_cross_entropy_with_logits(logits, target)

    # Backpropagate so image.grad is populated
    loss.backward()

    

    # Build a vulnerability map from the image gradients. Sum absolute gradient across channels.
    # Result shape: (B, 1, H, W)
    if image.grad is None:
        vuln_map = torch.zeros((image.size(0), 1, image.size(2), image.size(3)), device=device)
    else:
        vuln_map = image.grad.detach().abs().sum(dim=1, keepdim=True)

    # Return the vulnerability map (on CPU) and the raw detector results for
    # further use. Detach and move results to CPU to avoid holding device
    # tensors with grad history in callers.
    return vuln_map.cpu(), results.detach().cpu()

def visualize_vulnerability_map(vuln_map: torch.Tensor, image: torch.Tensor | None = None, image_strength: float = 0.05) -> torch.Tensor:
    """Convert a vulnerability map to a visualizable overlay on the original image.

    The visualization intentionally darkens the original image strongly so the
    vulnerability (red) points stand out. If `image` is provided it will overlay
    a red heatmap representing `vuln_map` on top of a darkened image. If
    `image` is None, the function returns a 3-channel visualization of the
    normalized vulnerability map.

    Args:
        vuln_map: Tensor, shape (B, 1, H, W) or (B, H, W)
        image: Optional Tensor, shape (B, 3, H, W) or (3, H, W). Expected range [0,1] or [0,255].
        image_strength: How much of the original image to keep (0.0..1.0). Small
            values (e.g. 0.05) make the image nearly black so heatmap points are
            clearly visible.

    Returns:
        Tensor of shape (B, 3, H, W), values in [0, 1].
    """
    # Ensure vuln_map has shape (B,1,H,W)
    if vuln_map.ndim == 3:
        vuln_map = vuln_map.unsqueeze(1)

    # Normalize each map to [0, 1]
    vmin = vuln_map.amin(dim=(2, 3), keepdim=True)
    vmax = vuln_map.amax(dim=(2, 3), keepdim=True)
    norm_map = (vuln_map - vmin) / (vmax - vmin + 1e-8)

    # If no image provided, return a 3-channel gray->RGB map (all channels equal)
    if image is None:
        vis_map = norm_map.repeat(1, 3, 1, 1)
        return vis_map.clamp(0.0, 1.0)

    # Prepare image tensor
    img = image
    if img.ndim == 3:
        # add batch dim
        img = img.unsqueeze(0)

    # Move to same device
    img = img.to(norm_map.device).float()

    # If image in [0,255], scale to [0,1]
    if img.max() > 2.0:
        img = img / 255.0

    # Ensure image has 3 channels
    if img.size(1) == 1:
        img = img.repeat(1, 3, 1, 1)

    # Create a red heatmap from norm_map: heatmap = (R,G,B) with R=norm, G=R*0.2, B=0
    heat = torch.zeros_like(img)
    heat_r = norm_map.squeeze(1)
    # expand to (B,1,H,W) then broadcast
    heat[:, 0:1, :, :] = heat_r
    heat[:, 1:2, :, :] = heat_r * 0.2
    heat[:, 2:3, :, :] = 0.0

    # Darken the original image so heatmap points are more visible.
    image_strength = float(image_strength)
    image_strength = max(0.0, min(1.0, image_strength))
    heat_strength = 1.0 - image_strength

    overlay = img * image_strength + heat * heat_strength

    return overlay.clamp(0.0, 1.0)

def plot_triple_res(image, vuln_map, mask):
    """Plot original image, vulnerability map visualization, and mask.

    This function is batch-size independent: if inputs have a batch dimension
    (B, C, H, W) it will plot each sample as a row with three columns.
    """
    # Ensure tensors have batch dimension
    if image.ndim == 3:
        image = image.unsqueeze(0)
    if vuln_map.ndim == 3:
        vuln_map = vuln_map.unsqueeze(0)
    if mask.ndim == 3:
        mask = mask.unsqueeze(0)

    B = image.size(0)

    # Prepare visualization map: if vuln_map is single-channel, convert to 3-channel vis
    if vuln_map.ndim == 4 and vuln_map.size(1) == 1:
        vis_map = visualize_vulnerability_map(vuln_map, image=None)
    else:
        # assume vuln_map is already a 3-channel visualization
        vis_map = vuln_map
        if vis_map.ndim == 3:
            vis_map = vis_map.unsqueeze(0)

    # Create subplots: rows = B, cols = 3
    fig, axes = plt.subplots(B, 3, figsize=(3 * 4, max(1, B) * 4))

    # Normalize axes shape to [B,3]
    if B == 1:
        axes = axes.reshape(1, 3)

    for i in range(B):
        ax0 = axes[i, 0]
        ax1 = axes[i, 1]
        ax2 = axes[i, 2]

        # Original image: ensure shape (3,H,W) and values in [0,1]
        print(f"image shape: {image.shape}, vuln_map shape: {vuln_map.shape}, mask shape: {mask.shape}")
        img = image[i].cpu().float()
        if img.max() > 2.0:
            img = img / 255.0
        if img.size(0) == 1:
            img = img.repeat(3, 1, 1)
        ax0.imshow(img.permute(1, 2, 0).numpy())
        ax0.set_title(f"Original Image {i}")
        ax0.axis('off')

        # Vulnerability visualization
        vm = vis_map[i].cpu().float()
        if vm.size(0) == 1:
            vm = vm.repeat(3, 1, 1)
        ax1.imshow(vm.permute(1, 2, 0).numpy())
        ax1.set_title("Vulnerability Map")
        ax1.axis('off')

        # Mask: reduce to (H,W)
        m = mask[i].cpu()
        if m.ndim == 3 and m.size(0) == 1:
            m_np = m.squeeze(0).numpy()
        elif m.ndim == 3 and m.size(0) == 3:
            # possibly RGB mask, convert to grayscale
            m_np = m.mean(0).numpy()
        else:
            m_np = m.numpy()
        ax2.imshow(m_np, cmap='gray')
        ax2.set_title("Inpainting Mask")
        ax2.axis('off')

    plt.tight_layout()
    plt.show()