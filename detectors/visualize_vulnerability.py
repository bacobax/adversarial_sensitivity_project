#!/usr/bin/env python3
"""
Vulnerability Visualization Script

This script iterates through a dataset folder and generates vulnerability
visualizations for detectors that implement the `visualize_vulnerability_grid` method.

Dataset structure expected:
    data_folder/
    ├── b-free/                    # Benign (non-attacked) images
    │   ├── real/                  # Original real images
    │   ├── samecat/               # Inpainted with same category
    │   ├── diffcat/               # Inpainted with different category
    │   ├── mask/                  # Masks for samecat inpainting (b&w)
    │   └── bbox/                  # Bboxes for diffcat inpainting (b&w)
    └── adv_attacks/               # Adversarial attacked images
        └── [model]/               # Model-specific attacks (e.g., R50_nodown, AnomalyOV)
            └── [attack_type]/     # e.g., pgd, fgsm, deepfool
                ├── real/          # Attacked real images
                ├── samecat/       # Attacked samecat images
                └── diffcat/       # Attacked diffcat images

If adversarial images for a model don't exist, they will be generated on-the-fly
and saved to the appropriate folder for future use.

Usage:
    python visualize_vulnerability.py \\
        --data_folder ./datasets/my_dataset \\
        --output_folder ./vulnerability_visualizations \\
        --attack_type pgd \\
        --detector AnomalyOV

Example:
    python visualize_vulnerability.py \\
        --data_folder ./datasets/coco_inpaint \\
        --output_folder ./output_viz \\
        --attack_type pgd \\
        --detector AnomalyOV \\
        --limit 10 \\
        --device mps
"""

import os
import sys
import argparse
from typing import Optional, List, Dict, Tuple, Any
from dataclasses import dataclass, field

import torch
import numpy as np
from PIL import Image
from tqdm import tqdm

# Setup paths
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
if SCRIPT_DIR not in sys.path:
    sys.path.insert(0, SCRIPT_DIR)

# Import detector utilities
from support.detect_utils import get_device
from support.metrics import compute_mask_anomaly_metrics, MetricsAggregator, load_mask_image


def to_numpy(data):
    """
    Safely convert a tensor or array to numpy array.
    Handles CUDA tensors, CPU tensors, and numpy arrays.
    """
    if data is None:
        return None
    if isinstance(data, np.ndarray):
        return data
    if isinstance(data, torch.Tensor):
        # Move to CPU and convert to numpy
        return data.detach().cpu().numpy()
    # Try to convert other types via numpy
    return np.asarray(data)


def get_cached_map(detector, image_path: str, cache: dict, map_size: tuple = None) -> tuple:
    """
    Get explanation map for an image, using cache to avoid recomputation.
    
    Args:
        detector: Detector instance with predict_with_map method
        image_path: Path to the image
        cache: Dictionary for caching results (key: path, value: (conf, map))
        map_size: Optional size for the map
        
    Returns:
        tuple: (confidence, map) or (None, None) if failed
    """
    if image_path in cache:
        return cache[image_path]
    
    try:
        if hasattr(detector, 'predict_with_map'):
            if map_size:
                conf, exp_map = detector.predict_with_map(image_path, map_size=map_size)
            else:
                conf, exp_map = detector.predict_with_map(image_path)
            cache[image_path] = (conf, exp_map)
            return conf, exp_map
    except Exception as e:
        pass
    
    cache[image_path] = (None, None)
    return None, None


@dataclass
class ImageSet:
    """Container for all image paths related to a single sample."""
    filename: str
    # Benign images
    real: str
    samecat: str
    diffcat: str
    mask: str
    bbox: str
    # Adversarial images (can be None if not yet generated)
    real_adv: Optional[str] = None
    samecat_adv: Optional[str] = None
    diffcat_adv: Optional[str] = None
    # Expected paths for adversarial images (where to save if generated)
    real_adv_expected: Optional[str] = None
    samecat_adv_expected: Optional[str] = None
    diffcat_adv_expected: Optional[str] = None


def get_detector_class(detector_name: str):
    """
    Dynamically load a detector class by name.
    
    Args:
        detector_name: Name of the detector (e.g., 'AnomalyOV')
        
    Returns:
        Detector class
    """
    DETECTOR_MAP = {
        'AnomalyOV': ('AnomalyOVDetector', os.path.join('models', 'anomaly_ov', 'detector.py')),
        'CLIP-D': ('CLIPDDetector', os.path.join('models', 'CLIP-D', 'detector.py')),
        'NPR': ('NPRDetector', os.path.join('models', 'NPR', 'detector.py')),
        'R50_nodown': ('R50NoDownDetector', os.path.join('models', 'R50_nodown', 'detector.py')),
        'R50_TF': ('R50TFDetector', os.path.join('models', 'R50_TF', 'detector.py')),
        'P2G': ('P2GDetector', os.path.join('models', 'P2G', 'detector.py')),
    }
    
    if detector_name not in DETECTOR_MAP:
        available = ', '.join(DETECTOR_MAP.keys())
        raise ValueError(f"Unknown detector: {detector_name}. Available: {available}")
    
    class_name, module_path = DETECTOR_MAP[detector_name]
    full_path = os.path.join(SCRIPT_DIR, module_path)
    
    import importlib.util
    spec = importlib.util.spec_from_file_location(detector_name, full_path)
    module = importlib.util.module_from_spec(spec)
    sys.modules[detector_name] = module
    spec.loader.exec_module(module)
    
    return getattr(module, class_name)


def get_available_detectors() -> List[str]:
    """Return list of available detector names."""
    return ['AnomalyOV', 'CLIP-D', 'NPR', 'R50_nodown', 'R50_TF', 'P2G']


def parse_detector_weights(weights_str: str) -> dict:
    """Parse detector weights specification string."""
    if not weights_str:
        return {}
    
    weights_dict = {}
    
    if ':' not in weights_str or (len(weights_str) > 1 and weights_str[1] == ':' and weights_str[0].isalpha()):
        weights_dict['_default'] = weights_str
    else:
        pairs = weights_str.split(',')
        for pair in pairs:
            pair = pair.strip()
            if not pair:
                continue
            
            if len(pair) > 2 and pair[1] == ':' and pair[0].isalpha():
                rest = pair[2:]
                colon_idx = rest.find(':')
                if colon_idx == -1:
                    weights_dict['_default'] = pair
                else:
                    first_colon = pair.find(':')
                    detector_name = pair[:first_colon]
                    path = pair[first_colon + 1:]
                    weights_dict[detector_name] = path
            else:
                colon_idx = pair.find(':')
                if colon_idx == -1:
                    weights_dict['_default'] = pair
                else:
                    detector_name = pair[:colon_idx]
                    path = pair[colon_idx + 1:]
                    weights_dict[detector_name] = path
    
    return weights_dict


def list_images(folder: str) -> List[str]:
    """List all image files in a folder (non-recursive)."""
    exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    files = []
    if not os.path.isdir(folder):
        return files
    for f in os.listdir(folder):
        if os.path.splitext(f)[1].lower() in exts:
            files.append(f)
    files.sort()
    return files


def find_file_with_extensions(base_path: str) -> Optional[str]:
    """Try to find a file with different image extensions."""
    if os.path.exists(base_path):
        return base_path
    
    base, ext = os.path.splitext(base_path)
    for new_ext in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']:
        new_path = base + new_ext
        if os.path.exists(new_path):
            return new_path
    return None


def validate_dataset_structure(data_folder: str, attack_type: str, model_name: str = None) -> bool:
    """
    Validate the dataset folder structure.
    
    Args:
        data_folder: Root data folder
        attack_type: Type of attack (pgd, fgsm, deepfool)
        model_name: Model name for model-specific adversarial folders (optional)
    
    Returns:
        True if b-free structure is valid (adversarial folders are optional now)
    """
    required_bfree = ['real', 'samecat', 'diffcat', 'mask', 'bbox']
    
    # Check b-free folders (required)
    bfree_folder = os.path.join(data_folder, 'b-free')
    if not os.path.isdir(bfree_folder):
        print(f"Error: b-free folder not found: {bfree_folder}")
        return False
    
    for folder in required_bfree:
        folder_path = os.path.join(bfree_folder, folder)
        if not os.path.isdir(folder_path):
            print(f"Error: Required b-free subfolder missing: {folder_path}")
            return False
    
    # Adversarial folders are optional - will be created if needed
    # Just ensure adv_attacks base folder exists or can be created
    adv_base = os.path.join(data_folder, 'adv_attacks')
    if not os.path.isdir(adv_base):
        print(f"Note: adv_attacks folder not found, will be created when generating attacks")
    
    return True


def collect_image_sets_for_model(
    data_folder: str, 
    attack_type: str, 
    model_name: str
) -> List[ImageSet]:
    """
    Collect all image sets from the dataset for a specific model.
    
    The new structure is:
        adv_attacks/[model_name]/[attack_type]/[real|samecat|diffcat]/
    
    If adversarial images don't exist, paths are set to None but expected paths
    are populated so they can be generated and saved.
    
    Args:
        data_folder: Root data folder
        attack_type: Type of attack (pgd, fgsm, deepfool)
        model_name: Model name for model-specific adversarial folders
    
    Returns:
        List of ImageSet objects (benign paths always set, adv paths may be None)
    """
    bfree_folder = os.path.join(data_folder, 'b-free')
    adv_folder = os.path.join(data_folder, 'adv_attacks', model_name, attack_type)
    
    # Get filenames from real folder (use as reference)
    real_folder = os.path.join(bfree_folder, 'real')
    filenames = list_images(real_folder)
    
    image_sets = []
    missing_benign = []
    
    for filename in filenames:
        # Build paths for benign images
        real_path = os.path.join(bfree_folder, 'real', filename)
        samecat_path = find_file_with_extensions(os.path.join(bfree_folder, 'samecat', filename))
        diffcat_path = find_file_with_extensions(os.path.join(bfree_folder, 'diffcat', filename))
        mask_path = find_file_with_extensions(os.path.join(bfree_folder, 'mask', filename))
        bbox_path = find_file_with_extensions(os.path.join(bfree_folder, 'bbox', filename))
        
        # Check for missing benign files (these are required)
        missing = []
        if not os.path.exists(real_path):
            missing.append('real')
        if samecat_path is None:
            missing.append('samecat')
        if diffcat_path is None:
            missing.append('diffcat')
        if mask_path is None:
            missing.append('mask')
        if bbox_path is None:
            missing.append('bbox')
        
        if missing:
            missing_benign.append((filename, missing))
            continue
        
        # Build paths for adversarial images (may or may not exist)
        real_adv_path = find_file_with_extensions(os.path.join(adv_folder, 'real', filename))
        samecat_adv_path = find_file_with_extensions(os.path.join(adv_folder, 'samecat', filename))
        diffcat_adv_path = find_file_with_extensions(os.path.join(adv_folder, 'diffcat', filename))
        
        # Expected paths for saving generated adversarial images
        # Use .png format for generated images
        base_name = os.path.splitext(filename)[0]
        real_adv_expected = os.path.join(adv_folder, 'real', f"{base_name}.png")
        samecat_adv_expected = os.path.join(adv_folder, 'samecat', f"{base_name}.png")
        diffcat_adv_expected = os.path.join(adv_folder, 'diffcat', f"{base_name}.png")
        
        image_sets.append(ImageSet(
            filename=filename,
            real=real_path,
            samecat=samecat_path,
            diffcat=diffcat_path,
            mask=mask_path,
            bbox=bbox_path,
            real_adv=real_adv_path,
            samecat_adv=samecat_adv_path,
            diffcat_adv=diffcat_adv_path,
            real_adv_expected=real_adv_expected,
            samecat_adv_expected=samecat_adv_expected,
            diffcat_adv_expected=diffcat_adv_expected,
        ))
    
    if missing_benign:
        print(f"Warning: {len(missing_benign)} files have missing benign components:")
        for fname, missing in missing_benign[:5]:
            print(f"  {fname}: missing {missing}")
        if len(missing_benign) > 5:
            print(f"  ... and {len(missing_benign) - 5} more")
    
    return image_sets


# Keep the old function for backward compatibility
def collect_image_sets(data_folder: str, attack_type: str) -> List[ImageSet]:
    """
    Collect all image sets from the dataset (legacy format without model subfolder).
    
    This is kept for backward compatibility. For model-specific adversarial images,
    use collect_image_sets_for_model() instead.
    """
    bfree_folder = os.path.join(data_folder, 'b-free')
    adv_folder = os.path.join(data_folder, 'adv_attacks', attack_type)
    
    # Get filenames from real folder (use as reference)
    real_folder = os.path.join(bfree_folder, 'real')
    filenames = list_images(real_folder)
    
    image_sets = []
    missing_files = []
    
    for filename in filenames:
        base_name = os.path.splitext(filename)[0]
        
        # Build paths for all images
        real_path = os.path.join(bfree_folder, 'real', filename)
        samecat_path = find_file_with_extensions(os.path.join(bfree_folder, 'samecat', filename))
        diffcat_path = find_file_with_extensions(os.path.join(bfree_folder, 'diffcat', filename))
        mask_path = find_file_with_extensions(os.path.join(bfree_folder, 'mask', filename))
        bbox_path = find_file_with_extensions(os.path.join(bfree_folder, 'bbox', filename))
        
        real_adv_path = find_file_with_extensions(os.path.join(adv_folder, 'real', filename))
        samecat_adv_path = find_file_with_extensions(os.path.join(adv_folder, 'samecat', filename))
        diffcat_adv_path = find_file_with_extensions(os.path.join(adv_folder, 'diffcat', filename))
        
        # Check for missing files
        missing = []
        if not os.path.exists(real_path):
            missing.append('real')
        if samecat_path is None:
            missing.append('samecat')
        if diffcat_path is None:
            missing.append('diffcat')
        if mask_path is None:
            missing.append('mask')
        if bbox_path is None:
            missing.append('bbox')
        if real_adv_path is None:
            missing.append(f'adv/{attack_type}/real')
        if samecat_adv_path is None:
            missing.append(f'adv/{attack_type}/samecat')
        if diffcat_adv_path is None:
            missing.append(f'adv/{attack_type}/diffcat')
        
        if missing:
            missing_files.append((filename, missing))
            continue
        
        image_sets.append(ImageSet(
            filename=filename,
            real=real_path,
            samecat=samecat_path,
            diffcat=diffcat_path,
            mask=mask_path,
            bbox=bbox_path,
            real_adv=real_adv_path,
            samecat_adv=samecat_adv_path,
            diffcat_adv=diffcat_adv_path,
        ))
    
    if missing_files:
        print(f"Warning: {len(missing_files)} files have missing components:")
        for fname, missing in missing_files[:5]:
            print(f"  {fname}: missing {missing}")
        if len(missing_files) > 5:
            print(f"  ... and {len(missing_files) - 5} more")
    
    return image_sets


def main():
    parser = argparse.ArgumentParser(
        description='Generate vulnerability visualizations for detector models.',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--data_folder',
        type=str,
        required=True,
        help='Parent data folder containing b-free/ and adv_attacks/ subfolders'
    )
    parser.add_argument(
        '--output_folder', '-o',
        type=str,
        required=True,
        help='Output folder for saving visualizations'
    )
    parser.add_argument(
        '--attack_type', '-a',
        type=str,
        nargs='+',
        required=True,
        help='Attack type(s) to use (e.g., pgd, fgsm, deepfool). Can specify multiple attacks separated by space. Must match folder names in adv_attacks/'
    )
    parser.add_argument(
        '--detector', '-d',
        type=str,
        default='AnomalyOV',
        nargs='+',
        help='Detector(s) to use. Can specify multiple detectors separated by space (default: AnomalyOV)'
    )
    parser.add_argument(
        '--weights', '-w',
        type=str,
        default=None,
        help='Path to model weights. For multiple detectors, use format: "detector1:path1,detector2:path2".'
    )
    parser.add_argument(
        '--limit', '-l',
        type=int,
        default=0,
        help='Limit number of images to process (0 = no limit)'
    )
    parser.add_argument(
        '--device',
        type=str,
        default=None,
        help='Device to use (default: auto-detect)'
    )
    parser.add_argument(
        '--dpi',
        type=int,
        default=150,
        help='DPI for saved images (default: 150)'
    )
    parser.add_argument(
        '--overlay_alpha',
        type=float,
        default=0.4,
        help='Alpha for map overlays (default: 0.4)'
    )
    parser.add_argument(
        '--visualize_limit',
        type=int,
        default=5,
        help='Number of samples to visualize (default: 5). Set to 0 to visualize all.'
    )
    parser.add_argument(
        '--skip_visualization',
        action='store_true',
        help='Skip visualization entirely, only compute metrics'
    )
    parser.add_argument(
        '--image_types',
        type=str,
        nargs='+',
        default=['samecat', 'diffcat'],
        choices=['real', 'samecat', 'diffcat'],
        help='Image types to process (default: samecat diffcat). Real images have no mask for metrics.'
    )
    
    args = parser.parse_args()
    
    # Validate data folder exists
    if not os.path.isdir(args.data_folder):
        print(f"Error: Data folder does not exist: {args.data_folder}")
        sys.exit(1)
    
    # Normalize attack type list
    attack_types = args.attack_type if isinstance(args.attack_type, list) else [args.attack_type]
    
    # Validate dataset structure (only checks b-free, adv is optional now)
    for attack_type in attack_types:
        if not validate_dataset_structure(args.data_folder, attack_type):
            sys.exit(1)
    
    print(f"Data folder: {args.data_folder}")
    print(f"Attack type(s): {', '.join(attack_types)}")
    
    # Get device
    if args.device:
        device = torch.device(args.device)
    else:
        device = get_device()
    print(f"Using device: {device}")
    
    # Parse weights specification
    weights_dict = parse_detector_weights(args.weights) if args.weights else {}
    
    # Normalize detector list
    detector_names = args.detector if isinstance(args.detector, list) else [args.detector]
    
    # Load all detectors
    detectors = {}
    for detector_name in detector_names:
        print(f"Loading detector: {detector_name}")
        try:
            DetectorClass = get_detector_class(detector_name)
            detector = DetectorClass(device=device)
            
            # Get weights for this detector
            if detector_name in weights_dict:
                weights_path = weights_dict[detector_name]
            elif '_default' in weights_dict and len(detector_names) == 1:
                weights_path = weights_dict['_default']
            else:
                weights_path = None
            
            if weights_path:
                print(f"  Using weights: {weights_path}")
            else:
                print(f"  Using default weights")
            
            detector.load(weights_path)
            
            # Check if detector supports visualize_vulnerability_grid
            if not hasattr(detector, 'visualize_vulnerability_grid'):
                print(f"Warning: Detector {detector_name} does not have visualize_vulnerability_grid method, skipping")
                continue
            
            detectors[detector_name] = detector
            
        except Exception as e:
            print(f"Error loading detector {detector_name}: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    if not detectors:
        print("Error: No detectors were loaded successfully")
        sys.exit(1)
    
    print(f"\nLoaded {len(detectors)} detector(s): {', '.join(detectors.keys())}")
    
    # Create output folder
    os.makedirs(args.output_folder, exist_ok=True)
    
    # Process images with each attack type and detector
    total_successful = 0
    total_failed = 0
    total_generated = 0
    
    for attack_type in attack_types:
        print(f"\n{'='*60}")
        print(f"Processing attack type: {attack_type}")
        print(f"{'='*60}")
        
        for detector_name, detector in detectors.items():
            print(f"\n--- Processing {detector_name} with {attack_type} ---")
            
            # Collect image sets for this specific model
            image_sets = collect_image_sets_for_model(
                args.data_folder, 
                attack_type, 
                detector_name
            )
        
        if args.limit > 0:
            image_sets = image_sets[:args.limit]
        
        if not image_sets:
            print(f"No image sets found for {detector_name}")
            continue
        
        # Count how many need adversarial generation
        needs_generation = sum(
            1 for img_set in image_sets 
            if img_set.real_adv is None or img_set.samecat_adv is None or img_set.diffcat_adv is None
        )
        
        print(f"Found {len(image_sets)} image sets")
        if needs_generation > 0:
            print(f"  {needs_generation} need adversarial image generation")
        
        # Create detector-specific output subfolder with attack_type
        # New structure: [output]/[model]/[attack_type]/
        detector_output = os.path.join(args.output_folder, detector_name, attack_type)

        os.makedirs(detector_output, exist_ok=True)
        
        # Initialize metrics aggregators for this detector
        metrics_exp = MetricsAggregator()  # Explanation map vs mask
        metrics_vuln = MetricsAggregator()  # Vulnerability map vs mask
        
        successful = 0
        failed = 0
        generated = 0
        visualized = 0
        
        # Determine which samples to visualize
        visualize_limit = args.visualize_limit if args.visualize_limit > 0 else len(image_sets)
        
        # Cache for computed maps to avoid duplicate GradCAM computations
        # Key: image_path, Value: (confidence, map)
        map_cache = {}
        
        for idx, image_set in enumerate(tqdm(image_sets, desc=f"{detector_name}/{attack_type}")):
                try:
                    # Process only requested image types (samecat, diffcat)
                    # Skip 'real' for metrics since there's no mask
                    for img_type in args.image_types:
                        # Skip real images for metrics computation (no ground truth mask)
                        if img_type == 'real':
                            continue
                        
                        # Get paths for this image type
                        benign_path = getattr(image_set, img_type)
                        adv_path = getattr(image_set, f"{img_type}_adv")
                        adv_expected = getattr(image_set, f"{img_type}_adv_expected")
                        
                        # Get mask path (use mask for samecat, bbox for diffcat)
                        if img_type == 'samecat':
                            mask_path = image_set.mask
                        elif img_type == 'diffcat':
                            mask_path = image_set.bbox
                        else:
                            mask_path = None
                        
                        if benign_path is None or not os.path.exists(benign_path):
                            continue
                    
                        # Load mask for metrics computation
                        mask = load_mask_image(mask_path) if mask_path else None
                        
                        # Compute explanation map on benign image (using cache)
                        exp_map = None
                        try:
                            if hasattr(detector, 'predict_with_map'):
                                _, exp_map = get_cached_map(detector, benign_path, map_cache)
                            elif hasattr(detector, 'predict_with_vulnerability'):
                                result = detector.predict_with_vulnerability(benign_path)
                                exp_map = result.get('anomaly_map')
                        except Exception as e:
                            print(f"\n  Warning: Could not get explanation map for {image_set.filename}/{img_type}: {e}")
                    
                        # Compute vulnerability map
                        # Strategy 1: Use predict_with_vulnerability if available (computes attack internally)
                        # Strategy 2: Generate adversarial separately and compute difference manually (faster for some detectors)
                        vuln_map = None
                        
                        # Only use predict_with_vulnerability for detectors that support it efficiently
                        # (AnomalyOV does, R50_nodown is too slow with it)
                        detector_name_check = detector_name.lower()
                        use_predict_with_vuln = hasattr(detector, 'predict_with_vulnerability') and 'anomaly' in detector_name_check
                        
                        if use_predict_with_vuln:
                            # Use the built-in vulnerability computation
                            try:
                                result = detector.predict_with_vulnerability(benign_path)
                                vuln_map = to_numpy(result.get('vulnerability_map'))
                                # If no vulnerability_map, use the difference between original and attacked
                                if vuln_map is None and result.get('anomaly_map_attacked') is not None:
                                    anom_orig = result.get('anomaly_map')
                                    anom_attacked = result.get('anomaly_map_attacked')
                                    if anom_orig is not None and anom_attacked is not None:
                                        vuln_map = np.abs(
                                            to_numpy(anom_attacked) - to_numpy(anom_orig)
                                        )
                            except Exception as e:
                                print(f"\n  Warning: Could not compute vulnerability map for {image_set.filename}/{img_type}: {e}")
                    
                        # For detectors without efficient predict_with_vulnerability, generate adversarial separately
                        if vuln_map is None and hasattr(detector, 'generate_adversarial') and hasattr(detector, 'predict_with_map'):
                            try:
                                if adv_path is None or not os.path.exists(adv_path if adv_path else ""):
                                    # Generate adversarial if not available
                                    adv_path = detector.generate_adversarial(
                                        image_path=benign_path,
                                        output_path=adv_expected,
                                        attack_type=attack_type,
                                        true_label=1,  # samecat/diffcat are fake
                                    )
                                    generated += 1
                                
                                # Compute map on adversarial (using cache)
                                if adv_path and os.path.exists(adv_path):
                                    _, adv_map = get_cached_map(detector, adv_path, map_cache)
                                    # Vulnerability is the difference
                                    if exp_map is not None and adv_map is not None:
                                        vuln_map = np.abs(to_numpy(adv_map) - to_numpy(exp_map))
                            except Exception as e:
                                print(f"\n  Warning: Could not compute vulnerability map for {image_set.filename}/{img_type}: {e}")
                    
                        # Compute metrics if mask is available
                        if mask is not None:
                            base_metadata = {
                                'filename': image_set.filename,
                                'image_type': img_type,
                                'attack_type': attack_type,
                            }
                            
                            # Metrics for explanation map vs mask
                            if exp_map is not None:
                                exp_metrics = compute_mask_anomaly_metrics(
                                    anomaly_map=exp_map,
                                    mask_image=mask,
                                    top_k=0.10,
                                    inpainted_is_white=True,
                                )
                                metrics_exp.update(exp_metrics, metadata=base_metadata)
                            
                            # Metrics for vulnerability map vs mask
                            if vuln_map is not None:
                                vuln_metrics = compute_mask_anomaly_metrics(
                                    anomaly_map=vuln_map,
                                    mask_image=mask,
                                    top_k=0.10,
                                    inpainted_is_white=True,
                                )
                                metrics_vuln.update(vuln_metrics, metadata=base_metadata)
                    
                    successful += 1
                    
                    # Visualize grid for a limited number of samples
                    if not args.skip_visualization and visualized < visualize_limit:
                        if hasattr(detector, 'visualize_vulnerability_grid'):
                            try:
                                base_name = os.path.splitext(image_set.filename)[0]
                                output_path = os.path.join(detector_output, f"{base_name}_grid.png")
                                
                                result = detector.visualize_vulnerability_grid(
                                    image_set=image_set,
                                    output_path=output_path,
                                    attack_type=attack_type,
                                    dpi=args.dpi,
                                    overlay_alpha=args.overlay_alpha,
                                    map_cache=map_cache,  # Pass cache to avoid recomputing maps
                                )
                                visualized += 1
                            except Exception as e:
                                print(f"\n  Warning: Visualization failed for {image_set.filename}: {e}")
                    
                except NotImplementedError as e:
                    print(f"\nError: {e}")
                    print(f"Detector {detector_name} does not support required methods.")
                    failed += len(image_sets) - successful - failed
                    break
                    
                except Exception as e:
                    print(f"\nFailed to process {image_set.filename}: {e}")
                    import traceback
                    traceback.print_exc()
                    failed += 1
                    continue
        
        # Save metrics to CSV
        # New structure: [output]/[model]/[attack_type]/metrics_[explanation|vulnerability].csv
        csv_base = os.path.join(detector_output, "metrics")
        
        if len(metrics_exp) > 0:
            exp_csv = f"{csv_base}_explanation.csv"
            metrics_exp.to_csv(exp_csv)
            print(f"\n  Explanation map metrics saved to: {exp_csv}")
            print(f"    Averages: {metrics_exp.summary_str()}")
        
        if len(metrics_vuln) > 0:
            vuln_csv = f"{csv_base}_vulnerability.csv"
            metrics_vuln.to_csv(vuln_csv)
            print(f"\n  Vulnerability map metrics saved to: {vuln_csv}")
            print(f"    Averages: {metrics_vuln.summary_str()}")
        
        print(f"\n{detector_name} ({attack_type}): {successful} processed, {failed} failed, {generated} adversarial generated, {visualized} visualized")
        total_successful += successful
        total_failed += failed
        total_generated += generated
    
    # Summary
    print(f"\n{'='*60}")
    print(f"Processing complete!")
    print(f"  Total Images Processed: {total_successful}")
    print(f"  Total Failed: {total_failed}")
    print(f"  Total Adversarial Images Generated: {total_generated}")
    print(f"  Image Types: {', '.join(args.image_types)}")
    print(f"  Attack Types: {', '.join(attack_types)}")
    print(f"  Output folder: {args.output_folder}")
    print(f"  Output structure: [output]/[model]/[attack_type]/metrics_[explanation|vulnerability].csv + mask images")
    print(f"{'='*60}")


if __name__ == '__main__':
    main()