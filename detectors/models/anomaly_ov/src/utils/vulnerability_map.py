import os
import sys
import torch
import torch.nn as nn
from typing import Any, Optional, Tuple
import torch.nn.functional as F
import matplotlib.pyplot as plt
from PIL import Image
import torchattacks as ta

# Setup paths for imports within the anomaly_ov package
_current_file = os.path.abspath(__file__)
_utils_dir = os.path.dirname(_current_file)
_src_dir = os.path.dirname(_utils_dir)
_project_root = os.path.dirname(_src_dir)
if _project_root not in sys.path:
    sys.path.insert(0, _project_root)
if _src_dir not in sys.path:
    sys.path.insert(0, _src_dir)


def _to_device_tensor(x: Any, device: str = "cpu") -> torch.Tensor:
    """Convert numpy/sequence/torch.Tensor to a torch.Tensor on device.

    Keeps tensors unchanged besides device transfer. Adds batch dim if missing
    for images/masks with shape (C,H,W).
    """
    if isinstance(x, torch.Tensor):
        t = x.to(device)
    else:
        t = torch.as_tensor(x).to(device)

    # If tensor has shape (C,H,W) assume single sample, add batch dim
    if t.ndim == 3:
        t = t.unsqueeze(0)

    return t
def predict_with_model(model, image_tensor: torch.Tensor, device, max_side=1024, anomaly_map_size=(224, 224), input_gradient=False, return_score_tensor=False):
    """Run model and optionally compute vulnerability (gradient) maps.

    Args:
        model: Llava model instance
        image_tensor: Tensor [1, V, 3, H, W]
        device: torch.device for model
        max_side: (unused here, resizing done before this function)
        anomaly_map_size: tuple passed to model
        input_gradient: if True compute gradient-based vulnerability maps

    Returns:
        score (float), attn_maps (Tensor), anomaly_map (Tensor), vuln_maps (Tensor or empty list), image_tensor_detached
        vuln_maps shape: [1, V, 1, H, W] when input_gradient True
    """
    # Ensure tensor on device & dtype
    image_tensor = image_tensor.to(device=device, dtype=torch.bfloat16)
    if input_gradient:
        image_tensor.requires_grad_(input_gradient)

    # print(f"image_tensor DEVICE: {image_tensor.device}")

    # Forward
    final_preds, attn_maps, anomaly_map = model.get_anomaly_fetures_from_images(
        image_tensor,
        with_attention_map=True,
        anomaly_map_size=anomaly_map_size
    )
    # print(f"final_preds: {final_preds} size_attn_maps: {attn_maps.shape} size_anomaly_map: {anomaly_map.shape}")

    vuln_maps = []
    if input_gradient:
        # Backward to populate image_tensor.grad (shape [1, V, 3, H, W])
        final_preds.backward()
        if image_tensor.grad is None:
            vuln_maps = torch.zeros((image_tensor.size(0), image_tensor.size(1), 1,
                                     image_tensor.size(3), image_tensor.size(4)), device=device)
        else:
            # Sum abs over channel dimension -> [1, V, 1, H, W]
            vuln_maps = image_tensor.grad.detach().abs().sum(dim=2, keepdim=True)

    if return_score_tensor:
        score = final_preds
    else:
        score = float(final_preds.detach().to(torch.float32).cpu().numpy().reshape(-1)[0])
    return score, attn_maps, anomaly_map, vuln_maps, image_tensor.detach()
    

def _normalize_anomaly_maps_shape(anomaly_maps: torch.Tensor) -> torch.Tensor:
    """Normalize anomaly_maps to shape [V, 1, H, W] on the same device/dtype.

    Accepts [V,1,H,W], [1,V,1,H,W], or [V,H,W]. Returns float tensor.
    """
    if anomaly_maps is None:
        raise ValueError("anomaly_maps is None")
    am = anomaly_maps
    if am.ndim == 5 and am.shape[0] == 1:
        am = am[0]
    if am.ndim == 3:
        am = am.unsqueeze(1)
    if not (am.ndim == 4 and am.shape[1] == 1):
        raise ValueError(f"Unsupported anomaly_maps shape: {tuple(anomaly_maps.shape)}")
    return am.to(dtype=torch.float32)


def build_topk_mask(anomaly_maps: torch.Tensor, top_k: float = 0.1) -> torch.Tensor:
    """Build per-view top-k mask from anomaly maps.

    Args:
        anomaly_maps: Tensor in shape [V,1,H,W] or [1,V,1,H,W] or [V,H,W]
        top_k: fraction (0,1] of highest anomaly scores per view to keep

    Returns:
        mask: Tensor of shape [1, V, 1, H, W], values in {0,1}, dtype float32
    """
    am = _normalize_anomaly_maps_shape(anomaly_maps)  # [V,1,H,W]
    V, _, H, W = am.shape
    am_flat = am.view(V, -1)
    N = am_flat.shape[1]
    k_int = max(1, min(N, int(round(top_k * N))))
    # Get thresholds per view by kth value
    # Sort descending
    sorted_vals, _ = torch.sort(am_flat, dim=1, descending=True)
    thr = sorted_vals[torch.arange(V), k_int - 1].view(V, 1, 1, 1)
    mask_v = (am >= thr).to(torch.float32)  # [V,1,H,W]
    return mask_v.unsqueeze(0)  # [1,V,1,H,W]


def generate_noise_like(x: torch.Tensor, mode: str = "random", blur_kernel: int = 7) -> torch.Tensor:
    """Generate noise with the same shape as x ([1,V,3,H,W]).

    Modes:
        - 'random': standard normal noise
        - 'structured': low-frequency noise via average pooling (blur)
    """
    noise = torch.randn_like(x)
    if mode == "structured":
        B, V, C, H, W = noise.shape
        noise_reshaped = noise.view(B * V, C, H, W)
        pad = blur_kernel // 2
        noise_blur = F.avg_pool2d(noise_reshaped, kernel_size=blur_kernel, stride=1, padding=pad)
        noise = noise_blur.view(B, V, C, H, W)
    return noise

class TorchAttackWrapper(nn.Module):
    def __init__(self, model, device, anomaly_map_size):
        super().__init__()
        self.model = model
        self.device = device
        self.anomaly_map_size = anomaly_map_size
        self.model.eval()  # ensure eval

    def forward(self, x_in):
        # x_in: [N, 3, H, W]
        x_views = x_in.unsqueeze(0)  # -> [1, N, 3, H, W] (V=N)
        score_t, _, _, _, _ = predict_with_model(
            model=self.model,
            image_tensor=x_views,
            device=self.device,
            anomaly_map_size=self.anomaly_map_size,
            return_score_tensor=True
        )
        score_t = score_t.reshape(-1).to(x_in.device, dtype=torch.float32)
        logits = torch.stack([1.0 - score_t, score_t], dim=1).expand(x_in.size(0), -1)  # -> [N, 2]
        return logits

def apply_topk_attack(
    model: nn.Module,
    device: str,
    image_tensor: torch.Tensor,
    anomaly_maps: torch.Tensor,
    epsilon: float = 0.05,
    top_k: float = 0.5,
    noise_mode: str = "random",
    clamp_min: float = -1.0,
    clamp_max: float = 1.0,
    true_label: int = 1,
) -> torch.Tensor:
    """Apply black-box top-k masked noise attack: x' = x + eps * M_topk âŠ™ eta.

    Args:
        model: OVAnomalyDetector model instance
        device: Device string (e.g., 'cpu', 'cuda')
        image_tensor: [1, V, 3, H, W]
        anomaly_maps: [V,1,H,W] or [1,V,1,H,W] or [V,H,W]
        epsilon: norm bound multiplier for noise
        top_k: fraction of highest anomaly scores to mask-in
        noise_mode: 'random', 'structured', 'fgsm', 'pgd', or 'deepfool'
        clamp_min, clamp_max: clamp range for normalized images
        true_label: True label of the image (0=real, 1=fake). Attack targets opposite class.

    Returns:
        attacked image tensor with same shape/type/device as input
    """
    x = image_tensor.detach().to(device)
    B, V, C, H, W = x.shape
    
    M = build_topk_mask(anomaly_maps, top_k=top_k).to(device=x.device)  # [1,V,1,H,W]
    
    # Resize mask to match image dimensions if needed
    if M.shape[-2:] != (H, W):
        # M is [1, V, 1, H_m, W_m], need to resize to [1, V, 1, H, W]
        M_reshaped = M.view(M.shape[0] * M.shape[1], M.shape[2], M.shape[3], M.shape[4])  # [B*V, 1, H_m, W_m]
        M_resized = F.interpolate(M_reshaped, size=(H, W), mode='bilinear', align_corners=False)
        M = M_resized.view(M.shape[0], M.shape[1], 1, H, W)  # [1, V, 1, H, W]
    
    if M.shape[0] == 1 and B > 1:
        M = M.expand(B, -1, -1, -1, -1)

    mode = noise_mode.lower()
    
    # Simple noise-based attacks
    if mode in ("random", "structured"):
        eta = generate_noise_like(x, mode=mode)
        perturb = epsilon * (M * eta)
        x_adv = (x + perturb).clamp(clamp_min, clamp_max)
        return x_adv
    
    # Gradient-based attacks using torchattacks
    x_flat = x.view(B * V, C, H, W)
    wrapper = TorchAttackWrapper(model, device, anomaly_map_size=(W, H)).to(device)

    if mode == "fgsm":
        attack = ta.FGSM(wrapper, eps=epsilon)
        try:
            attack.set_device(device)
        except Exception:
            pass  # some torchattacks versions don't have set_device
    elif mode == "pgd":
        attack = ta.PGD(wrapper, eps=epsilon)  # uses torchattacks defaults for alpha/steps
        try:
            attack.set_device(device)
        except Exception:
            pass  # some torchattacks versions don't have set_device
    elif mode == "deepfool":
        attack = ta.DeepFool(wrapper)          # default overshoot/steps
        try:
            attack.set_device(device)
        except Exception:
            pass  # some torchattacks versions don't have set_device
    else:
        raise ValueError(f"Unsupported noise_mode: {noise_mode}. "
                        f"Supported: 'random', 'structured', 'fgsm', 'pgd', 'deepfool'")

    # Target the OPPOSITE class to flip the prediction
    # true_label=1 (fake) -> target=0 (real), true_label=0 (real) -> target=1 (fake)
    target_class = 1 - true_label
    y = torch.full((B * V,), target_class, device=device, dtype=torch.long)
    x_adv_flat = attack(x_flat, y)
    x_adv_full = x_adv_flat.view(B, V, C, H, W)

    perturb = (x_adv_full - x) * M
    x_adv = (x + perturb).clamp(clamp_min, clamp_max)
    return x_adv


def adversarial_recompute(
    model,
    image_tensor: torch.Tensor,
    original_anomaly_maps: torch.Tensor,
    device: str,
    epsilon: float = 0.05,
    top_k: float = 0.5,
    noise_mode: str = "random",
    true_label: int = 1,
):
    """Create attacked image, re-run model, and get output_map = |a_map - a_map_adv|.

    Args:
        true_label: True label of the image (0=real, 1=fake). Attack targets opposite class.

    Returns: attacked_image [1,V,3,H,W], anomaly_maps_adv [V,1,H,W], output_map [V,1,H,W], adv_score
    """
    x_adv = apply_topk_attack(model=model, device=device,
                              image_tensor=image_tensor, anomaly_maps=original_anomaly_maps,
                              epsilon=epsilon, top_k=top_k, noise_mode=noise_mode,
                              true_label=true_label)
    
    # Get original anomaly map dimensions to ensure consistency
    am_orig = _normalize_anomaly_maps_shape(original_anomaly_maps)  # [V, 1, H_am, W_am]
    am_H, am_W = am_orig.shape[-2], am_orig.shape[-1]
    
    with torch.no_grad():
        adv_score, _, anomaly_maps_adv, _, _ = predict_with_model(
            model=model,
            image_tensor=x_adv,
            device=device,
            anomaly_map_size=(am_W, am_H),  # Use original anomaly map size for consistency
        )
    am_adv = _normalize_anomaly_maps_shape(anomaly_maps_adv)
    
    # Ensure both maps have the same size (resize if needed)
    if am_adv.shape[-2:] != am_orig.shape[-2:]:
        am_adv = F.interpolate(am_adv, size=(am_H, am_W), mode='bilinear', align_corners=False)
    
    output_map = (am_orig - am_adv).abs()
    return x_adv, am_adv, output_map, adv_score


def get_vulnerability_map(
        model,
        image_tensor: torch.Tensor,
        device: str = "cpu",
        anomaly_map_size: Tuple[int, int] = (224, 224),
    ) -> Tuple[torch.Tensor, float]:
    """
    Compute gradient-based vulnerability map for AnomalyOV model.
    
    This function computes the vulnerability map by backpropagating through
    the model and collecting gradients with respect to the input image.
    
    Args:
        model: OVAnomalyDetector model instance
        image_tensor: Input image tensor of shape [1, V, 3, H, W] or [B, 3, H, W]
        device: Device to run computation on
        anomaly_map_size: Size for anomaly map output
        
    Returns:
        vuln_map: Vulnerability map tensor of shape [B, 1, H, W]
        score: Anomaly score (float)
    """
    # Ensure tensor on device
    image_tensor = _to_device_tensor(image_tensor, device).float()
    
    # Ensure only the image requires grad
    image_tensor = image_tensor.clone().detach().to(device)
    image_tensor.requires_grad_(True)
    
    # Forward pass with gradient enabled
    score, _, anomaly_map, vuln_maps, _ = predict_with_model(
        model=model,
        image_tensor=image_tensor,
        device=device,
        anomaly_map_size=anomaly_map_size,
        input_gradient=True,
        return_score_tensor=False
    )
    
    # vuln_maps from predict_with_model already has shape [1, V, 1, H, W] when input_gradient=True
    # Reshape to [B, 1, H, W] format for consistency
    if isinstance(vuln_maps, torch.Tensor) and vuln_maps.numel() > 0:
        if vuln_maps.ndim == 5:
            # [1, V, 1, H, W] -> take first view or average across views
            vuln_map = vuln_maps.mean(dim=1)  # [1, 1, H, W]
        elif vuln_maps.ndim == 4:
            vuln_map = vuln_maps
        else:
            vuln_map = vuln_maps.view(1, 1, *vuln_maps.shape[-2:])
    else:
        # Fallback: create zero map
        H, W = image_tensor.shape[-2:]
        vuln_map = torch.zeros((1, 1, H, W), device=device)
    
    return vuln_map.cpu(), score


def get_exp_map(
        image: Image.Image,
        model,
        image_processor,
        device: str = "cpu",
        anomaly_map_size: Tuple[int, int] = (224, 224),
    ) -> Tuple[torch.Tensor, float]:
    """
    Compute gradient-based vulnerability/explanation map for AnomalyOV model.
    
    This is a convenience wrapper that handles PIL Image input and preprocessing.
    
    Args:
        image: PIL Image to analyze
        model: OVAnomalyDetector model instance
        image_processor: Image processor from the model (e.g., model.image_processor)
        device: Device to run computation on
        anomaly_map_size: Size for anomaly map output
        
    Returns:
        vuln_map: Vulnerability map tensor of shape [1, 1, H, W], on CPU
        score: Anomaly score (float, higher = more likely fake/anomalous)
    """
    # Preprocess image using the model's image processor
    if not isinstance(image, Image.Image):
        image = Image.fromarray(image) if hasattr(image, '__array__') else image
    
    processed = image_processor.preprocess([image], return_tensors='pt')
    pixel_values = processed['pixel_values'][0]
    
    if not isinstance(pixel_values, torch.Tensor):
        pixel_values = torch.tensor(pixel_values)
    
    # Add batch dimension: [3, H, W] -> [1, 1, 3, H, W] for AnomalyOV
    # The model expects [1, V, 3, H, W] where V is number of views
    pixel_values = pixel_values.unsqueeze(0).unsqueeze(0)  # [1, 1, 3, H, W]
    
    return get_vulnerability_map(
        model=model,
        image_tensor=pixel_values,
        device=device,
        anomaly_map_size=anomaly_map_size,
    )


def visualize_vulnerability_map(vuln_map: torch.Tensor, image: Optional[torch.Tensor] = None, image_strength: float = 0.05) -> torch.Tensor:
    """Convert a vulnerability map to a visualizable overlay on the original image.

    The visualization intentionally darkens the original image strongly so the
    vulnerability (red) points stand out. If `image` is provided it will overlay
    a red heatmap representing `vuln_map` on top of a darkened image. If
    `image` is None, the function returns a 3-channel visualization of the
    normalized vulnerability map.

    Args:
        vuln_map: Tensor, shape (B, 1, H, W) or (B, H, W)
        image: Optional Tensor, shape (B, 3, H, W) or (3, H, W). Expected range [0,1] or [0,255].
        image_strength: How much of the original image to keep (0.0..1.0). Small
            values (e.g. 0.05) make the image nearly black so heatmap points are
            clearly visible.

    Returns:
        Tensor of shape (B, 3, H, W), values in [0, 1].
    """
    # Ensure vuln_map has shape (B,1,H,W)
    if vuln_map.ndim == 3:
        vuln_map = vuln_map.unsqueeze(1)

    # Normalize each map to [0, 1]
    vmin = vuln_map.amin(dim=(2, 3), keepdim=True)
    vmax = vuln_map.amax(dim=(2, 3), keepdim=True)
    norm_map = (vuln_map - vmin) / (vmax - vmin + 1e-8)

    # If no image provided, return a 3-channel gray->RGB map (all channels equal)
    if image is None:
        vis_map = norm_map.repeat(1, 3, 1, 1)
        return vis_map.clamp(0.0, 1.0)

    # Prepare image tensor
    img = image
    if img.ndim == 3:
        # add batch dim
        img = img.unsqueeze(0)

    # Move to same device
    img = img.to(norm_map.device).float()

    # If image in [0,255], scale to [0,1]
    if img.max() > 2.0:
        img = img / 255.0

    # Ensure image has 3 channels
    if img.size(1) == 1:
        img = img.repeat(1, 3, 1, 1)

    # Create a red heatmap from norm_map: heatmap = (R,G,B) with R=norm, G=R*0.2, B=0
    heat = torch.zeros_like(img)
    heat_r = norm_map.squeeze(1)
    # expand to (B,1,H,W) then broadcast
    heat[:, 0:1, :, :] = heat_r
    heat[:, 1:2, :, :] = heat_r * 0.2
    heat[:, 2:3, :, :] = 0.0

    # Darken the original image so heatmap points are more visible.
    image_strength = float(image_strength)
    image_strength = max(0.0, min(1.0, image_strength))
    heat_strength = 1.0 - image_strength

    overlay = img * image_strength + heat * heat_strength

    return overlay.clamp(0.0, 1.0)

def plot_triple_res(image, vuln_map, mask):
    """Plot original image, vulnerability map visualization, and mask.

    This function is batch-size independent: if inputs have a batch dimension
    (B, C, H, W) it will plot each sample as a row with three columns.
    """
    # Ensure tensors have batch dimension
    if image.ndim == 3:
        image = image.unsqueeze(0)
    if vuln_map.ndim == 3:
        vuln_map = vuln_map.unsqueeze(0)
    if mask.ndim == 3:
        mask = mask.unsqueeze(0)

    B = image.size(0)

    # Prepare visualization map: if vuln_map is single-channel, convert to 3-channel vis
    if vuln_map.ndim == 4 and vuln_map.size(1) == 1:
        vis_map = visualize_vulnerability_map(vuln_map, image=None)
    else:
        # assume vuln_map is already a 3-channel visualization
        vis_map = vuln_map
        if vis_map.ndim == 3:
            vis_map = vis_map.unsqueeze(0)

    # Create subplots: rows = B, cols = 3
    fig, axes = plt.subplots(B, 3, figsize=(3 * 4, max(1, B) * 4))

    # Normalize axes shape to [B,3]
    if B == 1:
        axes = axes.reshape(1, 3)

    for i in range(B):
        ax0 = axes[i, 0]
        ax1 = axes[i, 1]
        ax2 = axes[i, 2]

        # Original image: ensure shape (3,H,W) and values in [0,1]
        print(f"image shape: {image.shape}, vuln_map shape: {vuln_map.shape}, mask shape: {mask.shape}")
        img = image[i].cpu().float()
        if img.max() > 2.0:
            img = img / 255.0
        if img.size(0) == 1:
            img = img.repeat(3, 1, 1)
        ax0.imshow(img.permute(1, 2, 0).numpy())
        ax0.set_title(f"Original Image {i}")
        ax0.axis('off')

        # Vulnerability visualization
        vm = vis_map[i].cpu().float()
        if vm.size(0) == 1:
            vm = vm.repeat(3, 1, 1)
        ax1.imshow(vm.permute(1, 2, 0).numpy())
        ax1.set_title("Vulnerability Map")
        ax1.axis('off')

        # Mask: reduce to (H,W)
        m = mask[i].cpu()
        if m.ndim == 3 and m.size(0) == 1:
            m_np = m.squeeze(0).numpy()
        elif m.ndim == 3 and m.size(0) == 3:
            # possibly RGB mask, convert to grayscale
            m_np = m.mean(0).numpy()
        else:
            m_np = m.numpy()
        ax2.imshow(m_np, cmap='gray')
        ax2.set_title("Inpainting Mask")
        ax2.axis('off')

    plt.tight_layout()
    plt.show()