import os
import sys
import numpy as np
import torch
import torch.nn.functional as F
from typing import List, Dict, Tuple, Optional
from tqdm import tqdm
from PIL import Image
import matplotlib
# Use non-interactive backend for matplotlib to avoid display issues
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from pathlib import Path

# Add the detectors directory to the path for proper imports
DETECTORS_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if DETECTORS_DIR not in sys.path:
    sys.path.insert(0, DETECTORS_DIR)

class VulnerabilityAnalyzer:
    """
    Analyzes and visualizes the most vulnerable regions in a model by comparing
    Grad-CAM heatmaps between clean and adversarial examples.
    """
    
    def __init__(self, detector, device: torch.device, output_dir: str = 'vulnerability_maps'):
        """
        Initialize the vulnerability analyzer.
        
        Args:
            detector: The detector model to analyze
            device: Device to run computations on
            output_dir: Directory to save visualization outputs
        """
        self.detector = detector
        self.device = device
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Create output subdirectories
        (self.output_dir / 'vulnerability_maps').mkdir(exist_ok=True)
        (self.output_dir / 'visualizations').mkdir(exist_ok=True)
    
    def _load_and_preprocess(self, image_paths: List[str]) -> torch.Tensor:
        """Load and preprocess images for the WaveRep detector."""
        assert hasattr(self.detector, 'transform') and self.detector.transform is not None, \
            "Detector must have a transform method"
        
        images = []
        for path in image_paths:
            img = Image.open(path).convert('RGB')
            img_tensor = self.detector.transform(img)  # Use detector's transform
            images.append(img_tensor)
        
        return torch.stack(images).to(self.device)
    
    def _save_vulnerability_map(self, clean_path: str, diff_map: np.ndarray, method: str):
        """Save vulnerability map for a single image."""
        img_name = os.path.basename(clean_path)
        base_name = os.path.splitext(img_name)[0]
        
        # Save raw difference map
        map_dir = self.output_dir / 'vulnerability_maps' / method
        map_dir.mkdir(parents=True, exist_ok=True)
        np.save(map_dir / f"{base_name}.npy", diff_map)
        
        # Save visualization
        vis_dir = self.output_dir / 'visualizations' / method
        vis_dir.mkdir(parents=True, exist_ok=True)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        img = Image.open(clean_path).convert('RGB')
        plt.imshow(img)
        plt.axis('off')
        plt.title('Original')
        
        # Vulnerability map
        plt.subplot(1, 2, 2)
        plt.imshow(diff_map[0] if diff_map.ndim == 3 else diff_map, 
                  cmap='jet', 
                  vmin=0, vmax=1)
        plt.colorbar()
        plt.axis('off')
        plt.title('Vulnerability Map')
        
        # Save and close
        plt.tight_layout()
        plt.savefig(vis_dir / f"{base_name}.png", bbox_inches='tight', pad_inches=0.1)
        plt.close()
        
        print(f"Saved: {vis_dir}/{base_name}.png")
    
    def compute_gradcam_differences(self, clean_paths: List[str], adv_paths: List[str],
        method: str = 'gradcam', batch_size: int = 1,
        metrics: List[str] = None) -> Dict[str, Dict[str, np.ndarray]]:
        """
        Compute differences between clean and adversarial Grad-CAM maps using multiple metrics.

        Available metrics:
        - 'diff': Simple difference (adv - clean)
        - 'abs_diff': Absolute difference |adv - clean|
        - 'squared_diff': Squared difference (adv - clean)²
        - 'relative_diff': Relative difference (adv - clean) / (|clean| + ε)
        - 'ssim': Structural Similarity Index
        - 'l1': L1 norm of the difference
        - 'l2': L2 norm of the difference
        - 'cosine': Cosine similarity between the flattened maps

        Args:
            clean_paths: List of paths to clean images
            adv_paths: List of paths to corresponding adversarial images
            method: Explanation method to use
            batch_size: Batch size (kept for compatibility)
            metrics: List of metrics to compute. If None, uses all available metrics.
        """
        if metrics is None:
            metrics = ['diff', 'abs_diff', 'squared_diff', 'relative_diff', 'ssim', 'l1', 'l2', 'cosine']
            metrics = ['ssim', 'l1', 'l2', 'cosine']
        if type(metrics) == str:
            metrics = [metrics]
        
        from skimage.metrics import structural_similarity as ssim
        from scipy.spatial.distance import cosine as cosine_sim
        import numpy as np
        import torch
        from tqdm import tqdm
        
        results = {}
        EPS = 1e-8
        
        for clean_path, adv_path in tqdm(zip(clean_paths, adv_paths),
                                         total=len(clean_paths),
                                         desc="Processing images"):
            try:
                # Get clean and adversarial CAMs
                clean_batch = self._load_and_preprocess([clean_path])
                adv_batch = self._load_and_preprocess([adv_path])
                
                clean_batch.requires_grad_(True)
                adv_batch.requires_grad_(True)
                
                clean_cam, _ = self.detector.explain(batch=clean_batch, method=method, class_idx=None)
                adv_cam, _ = self.detector.explain(batch=adv_batch, method=method, class_idx=None)
                
                # Convert to numpy and squeeze batch dimension
                clean_cam = clean_cam.squeeze(0).detach().cpu().numpy()
                adv_cam = adv_cam.squeeze(0).detach().cpu().numpy()
                
                # Initialize metrics dictionary for this image
                img_metrics = {}
                
                # Compute all requested metrics
                if 'diff' in metrics:
                    img_metrics['diff'] = adv_cam - clean_cam
                
                if 'abs_diff' in metrics:
                    img_metrics['abs_diff'] = np.abs(adv_cam - clean_cam)
                
                if 'squared_diff' in metrics:
                    img_metrics['squared_diff'] = (adv_cam - clean_cam)**2
                
                if 'relative_diff' in metrics:
                    denom = np.abs(clean_cam) + EPS
                    img_metrics['relative_diff'] = (adv_cam - clean_cam) / denom
                
                if 'ssim' in metrics:
                    # SSIM requires 2D input, so we take mean across channels if needed
                    if clean_cam.ndim > 2:
                        ssim_scores = [ssim(clean_cam[i], adv_cam[i],
                                            data_range=adv_cam[i].max() - adv_cam[i].min())
                                       for i in range(clean_cam.shape[0])]
                        img_metrics['ssim'] = np.mean(ssim_scores)
                    else:
                        img_metrics['ssim'] = ssim(clean_cam, adv_cam,
                                                   data_range=adv_cam.max() - adv_cam.min())
                
                if 'l1' in metrics:
                    img_metrics['l1'] = np.abs(adv_cam - clean_cam).mean()
                
                if 'l2' in metrics:
                    img_metrics['l2'] = np.sqrt(((adv_cam - clean_cam)**2).mean())
                
                if 'cosine' in metrics:
                    # Flatten the arrays for cosine similarity
                    clean_flat = clean_cam.reshape(-1)
                    adv_flat = adv_cam.reshape(-1)
                    img_metrics['cosine'] = 1 - cosine_sim(clean_flat, adv_flat)
                
                # Save results for this image
                filename = os.path.basename(clean_path)
                results[filename] = img_metrics
                
                # Save visualizations for each metric
                for metric_name, metric_value in img_metrics.items():
                    # Skip scalar metrics for visualization
                    if not isinstance(metric_value, np.ndarray):
                        continue
                    self._save_vulnerability_map(clean_path, metric_value, f"{method}_{metric_name}")
            
            except Exception as e:
                print(f"Error processing {clean_path}: {str(e)}")
                continue
            
            finally:
                # Clean up
                if 'clean_batch' in locals():
                    del clean_batch
                if 'adv_batch' in locals():
                    del adv_batch
                if 'clean_cam' in locals():
                    del clean_cam
                if 'adv_cam' in locals():
                    del adv_cam
                if 'img_metrics' in locals():
                    del img_metrics
                torch.cuda.empty_cache()
        
        return results
    def visualize_vulnerability_maps(self, clean_paths: List[str], 
                                   vulnerability_maps: Dict[str, np.ndarray],
                                   alpha: float = 0.7) -> None:
        """
        This method is kept for backward compatibility but is no longer needed
        as visualization is now handled in _save_vulnerability_map.
        """
        pass

def analyze_vulnerability(detector, clean_folder: str, adv_folder: str, output_dir: str,
                         method: str = 'gradcam', batch_size: int = 8, device: torch.device = None, metrics: List[str] = None):
    """
    Convenience function to run vulnerability analysis from paths.
    
    Args:
        detector: The detector model to analyze
        clean_folder: Path to folder containing clean images
        adv_folder: Path to folder containing corresponding adversarial images
        output_dir: Directory to save outputs
        method: Explanation method to use
        batch_size: Batch size for processing
        device: Device to run computations on
    """
    from glob import glob
    from os.path import join, basename, splitext
    import re
    
    # Get all image files from both folders
    def get_image_files(folder):
        exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
        files = []
        for f in os.listdir(folder):
            ext = splitext(f)[1].lower()
            if ext in exts:
                files.append(join(folder, f))
        return sorted(files)
    
    clean_paths = get_image_files(clean_folder)
    adv_files = {basename(f): f for f in get_image_files(adv_folder)}
    
    # Match clean images to adversarial ones
    clean_matched = []
    adv_matched = []
    
    for clean_path in clean_paths:
        clean_name = basename(clean_path)
        
        # Try exact match first
        if clean_name in adv_files:
            clean_matched.append(clean_path)
            adv_matched.append(adv_files[clean_name])
            continue
            
        # Try to find matching file with different extension
        base_name = splitext(clean_name)[0]
        for adv_name, adv_path in adv_files.items():
            if adv_name.startswith(base_name):
                clean_matched.append(clean_path)
                adv_matched.append(adv_path)
                break
        else:
            print(f"Warning: No matching adversarial image for {clean_name}")
    
    if not clean_matched:
        raise ValueError("No matching image pairs found between clean and adversarial folders")
    
    print(f"Found {len(clean_matched)} matching image pairs")
    
    # Initialize analyzer
    analyzer = VulnerabilityAnalyzer(detector, device, output_dir)
    
    # Compute vulnerability maps
    print("Computing vulnerability maps...")
    vulnerability_maps = analyzer.compute_gradcam_differences(
        clean_matched, adv_matched, method, batch_size, metrics
    )
    
    # Generate visualizations
    print("Generating visualizations...")
    analyzer.visualize_vulnerability_maps(clean_matched, vulnerability_maps)
    
    print(f"Analysis complete. Results saved to {output_dir}")
