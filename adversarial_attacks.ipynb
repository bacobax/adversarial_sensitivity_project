{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c585d3e8",
   "metadata": {},
   "source": [
    "# Adversarial classification demo (clean vs attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0680e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils.dataset import get_dataloader, BatchedImageIterable\n",
    "from utils.nets import load_network\n",
    "from utils.adversarial_attacks import fgsm_attack, pgd_attack\n",
    "from utils.vulnerability_map import get_vulnerability_map, visualize_vulnerability_map, plot_triple_res\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f19759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Config\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "weights_dir = './weights/weights_AdversarialRobustnessCLIP'\n",
    "images_inpainted = './data/COCO_inpainted'\n",
    "images_real = './data/COCO_real'\n",
    "masks_dir = './data/masks'\n",
    "batch_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd5a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load detector and data loaders\n",
    "\n",
    "detector = load_network('OJHA_latent_clip', weights_dir).to(device).eval()\n",
    "is_resnet = type(detector).__name__ == 'ResNet'\n",
    "\n",
    "inpainted_loader = get_dataloader(\n",
    "    images_inpainted,\n",
    "    masks_dir,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    model=detector,\n",
    "    transform_img=detector.preprocess,\n",
    ")\n",
    "\n",
    "real_dataset = BatchedImageIterable(\n",
    "    images_dir=images_real,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    transform_img=detector.preprocess,\n",
    ")\n",
    "real_loader = DataLoader(real_dataset, batch_size=None, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8272d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helpers\n",
    "\n",
    "def classifier_probs(images: torch.Tensor):\n",
    "    logits = detector(images.to(device))\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    return logits, probs[:, 1].detach().cpu()\n",
    "\n",
    "\n",
    "def classify_with_attacks(images: torch.Tensor, label: int, fgsm_eps=4/255, pgd_eps=8/255, pgd_alpha=2/255, pgd_steps=10):\n",
    "    base = images.to(device)\n",
    "    labels = torch.full((base.size(0),), label, dtype=torch.long, device=device)\n",
    "    clamp_range = (float(base.min()), float(base.max()))\n",
    "\n",
    "    _, clean_prob = classifier_probs(base)\n",
    "    adv_fgsm = fgsm_attack(detector, base, labels, eps=fgsm_eps, post_clamp=clamp_range)\n",
    "    _, fgsm_prob = classifier_probs(adv_fgsm)\n",
    "\n",
    "    adv_pgd = pgd_attack(\n",
    "        detector,\n",
    "        base,\n",
    "        labels,\n",
    "        eps=pgd_eps,\n",
    "        alpha=pgd_alpha,\n",
    "        steps=pgd_steps,\n",
    "        random_start=True,\n",
    "        post_clamp=clamp_range,\n",
    "    )\n",
    "    _, pgd_prob = classifier_probs(adv_pgd)\n",
    "\n",
    "    print(f\"clean prob(fake): {clean_prob.tolist()}\")\n",
    "    print(f\"fgsm  prob(fake): {fgsm_prob.tolist()}\")\n",
    "    print(f\"pgd   prob(fake): {pgd_prob.tolist()}\")\n",
    "\n",
    "    return adv_fgsm, adv_pgd\n",
    "\n",
    "\n",
    "def show_vulnerability(image: torch.Tensor, mask: torch.Tensor, original: torch.Tensor, title: str = \"clean\"):\n",
    "    vmap, _ = get_vulnerability_map(image, mask, detector, is_resnet=is_resnet, device=device)\n",
    "    vis = visualize_vulnerability_map(vmap, original)\n",
    "    plot_triple_res(original, vis, mask)\n",
    "    _, prob = classifier_probs(image)\n",
    "    print(f\"[{title}] prob(fake): {prob.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inpainted sample: label=1 (fake)\n",
    "inpaint_image, inpaint_mask, inpaint_orig = next(iter(inpainted_loader))\n",
    "print(f'inpainted batch -> image: {tuple(inpaint_image.shape)}, mask: {tuple(inpaint_mask.shape)}')\n",
    "show_vulnerability(inpaint_image, inpaint_mask, inpaint_orig, title='inpainted clean')\n",
    "_ = classify_with_attacks(inpaint_image, label=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d38df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Real sample: label=0 (real)\n",
    "real_images, real_originals = next(iter(real_loader))\n",
    "real_mask = torch.zeros((real_images.size(0), 1, real_images.size(2), real_images.size(3)))\n",
    "print(f'real batch -> image: {tuple(real_images.shape)}')\n",
    "show_vulnerability(real_images, real_mask, real_originals, title='real clean')\n",
    "_ = classify_with_attacks(real_images, label=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advCLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
