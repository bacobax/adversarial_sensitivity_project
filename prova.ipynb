{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d046fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'support'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvulnerability_map\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualize_vulnerability_map, plot_triple_res\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainability_map\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_explainability_map\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdetectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mWaveRep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WaveRepDetector\n",
      "File \u001b[0;32m~/Desktop/school/unitn/adversarial_sensitivity_project/detectors/models/WaveRep/detector.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msupport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_detector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseDetector\n\u001b[1;32m     10\u001b[0m DETECTOR_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18m__file__\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DETECTOR_DIR \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'support'"
     ]
    }
   ],
   "source": [
    "from utils.dataset import get_dataloader\n",
    "from utils.vulnerability_map import visualize_vulnerability_map, plot_triple_res\n",
    "from utils.explainability_map import get_explainability_map\n",
    "from detectors.models.WaveRep.detector import WaveRepDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f00a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1d65740",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = './weights/weights_AdversarialRobustnessCLIP'\n",
    "detector = load_network('CORV_latent_r50', weights_dir).to(device)\n",
    "\n",
    "is_resnet = type(detector).__name__ == \"ResNet\"\n",
    "\n",
    "# Create dataloader AFTER loading the model so we can infer image size\n",
    "images_dir: str = \"./data/COCO_inpainted\"\n",
    "masks_dir: str = \"./data/masks\"\n",
    "dataloader = get_dataloader(\n",
    "    images_dir,\n",
    "    masks_dir,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    model=detector,\n",
    "    transform_img=detector.preprocess if not is_resnet else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, mask, original) in enumerate(dataloader):\n",
    "    print(f\"BATCH {i}: image.shape={image.shape}, mask.shape={mask.shape}\")\n",
    "    explain_map, logits = get_explainability_map(image, detector, is_resnet=is_resnet, device=device)\n",
    "    vis = visualize_vulnerability_map(explain_map, image)\n",
    "    plot_triple_res(original, vis, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcef038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader AFTER loading the model so we can infer image size\n",
    "from utils.dataset import BatchedImageIterable\n",
    "from torch.utils.data import DataLoader\n",
    "images_dir: str = \"./data/COCO_real\"\n",
    "masks_dir: str = \"./data/masks\"\n",
    "dataset = BatchedImageIterable(\n",
    "    images_dir,\n",
    "    batch_size=1,\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=1, num_workers=1)  # dataset yields pre-batched items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c58ae205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9729)\n",
      "tensor(0.9812)\n",
      "tensor(0.0741)\n",
      "tensor(0.9804)\n",
      "tensor(0.9473)\n",
      "tensor(0.5510)\n",
      "tensor(0.9593)\n",
      "tensor(0.8772)\n",
      "tensor(0.9951)\n",
      "tensor(0.8999)\n",
      "tensor(0.9843)\n",
      "tensor(0.9981)\n",
      "tensor(0.9480)\n",
      "tensor(0.7102)\n",
      "tensor(0.6353)\n",
      "tensor(0.9992)\n",
      "tensor(0.9924)\n",
      "tensor(0.9972)\n",
      "tensor(0.9794)\n",
      "tensor(0.2528)\n",
      "Average estimated probability of AI-generated content: 0.8367652732878923\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from utils.utils import Metric\n",
    "avg_estimate = Metric()\n",
    "for i, (image, mask, orig) in enumerate(dataloader):\n",
    "    with torch.no_grad():\n",
    "        logits = detector(image.to(device))\n",
    "        prob_ai = torch.sigmoid(logits[:, 1])\n",
    "        for p in prob_ai:\n",
    "            print(p)\n",
    "        avg_estimate.update(prob_ai.mean().item(), n=prob_ai.numel())\n",
    "        # res = detector(image.squeeze(0).to(device))[0][1]\n",
    "        # print(res)\n",
    "        # print(\"after sigmoid:\")\n",
    "        # print(F.sigmoid(res))\n",
    "        # prob_AI_gen = F.sigmoid(res)\n",
    "        # avg_estimate.update(prob_AI_gen.mean().item(), n=image.size(0))\n",
    "\n",
    "print(\"Average estimated probability of AI-generated content:\", avg_estimate.avg())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3a65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trends_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
